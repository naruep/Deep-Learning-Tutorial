{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Introduction\n",
    "\n",
    "### Experimental Background\n",
    "\n",
    "There is a large amount of information in images, which usually requires a lot of language to describe clearly. Among many processing images, classifying them will be the most essential task. In this experiment, we will use convolutional neural network to identify flowers in a real environment, and we will use Keras (backend tensorflow), a deep learning framework, to build a convolutional neural network model to solve the image classification problem.\n",
    "For the dataset, the pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they Photos are not reduced to a single size, they have different proportions.\n",
    "\n",
    "### Experimental environment\n",
    "\n",
    "- Huawei Modelarts platform\n",
    "    - work environment:Multi-Engine 1.0\n",
    "    - Instance Flavor:8 vCPUs | 32 GiB\n",
    "\n",
    "1. Python 3.6.5\n",
    "2. Tensorflow 1.13.1\n",
    "3. Kears 2.2.4\n",
    "- Matplotlib 3.2.2\n",
    "- Numpy 1.18.5\n",
    "- OpenCV 3.4.1\n",
    "\n",
    "### Purpose of the experiment.\n",
    "\n",
    "1. enhance the understanding of the process of building neural networks using Keras\n",
    "- Explore the impact that unbalanced data can have\n",
    "- Learn how to use mature models to make efficient use of existing datasets\n",
    "\n",
    "**<font color='red'>Note: Don't worry if WARNING or UserWarning appears in the run results, it won't affect the results. </font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce relevant python packages and modules\n",
    "\n",
    "All the functions needed for this experiment are already included here, allowing you to add your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.10.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers include common network layers. \n",
    "# optimizers include common optimizers. \n",
    "# Sequential is used to construct a linear (from beginning to end) network structure.\n",
    "# Model functional model, complex models can be constructed. \n",
    "from keras import layers, optimizers, Sequential, Model\n",
    "# contains models commonly used for migration learning. \n",
    "from keras import applications# is used for image enhancement. \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# common packages: control files and folders. \n",
    "import glob\n",
    "import os\n",
    "# cv2 = opencv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters related to dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset, which is used for training and verification.\n",
    "# path = '../DL _data/flower_photos/'\n",
    "path = '../Deep-Learning-Tutorial/DL _data/flower_photos/'\n",
    "# Scale images. The size is 128*128*3(width * height * channals)\n",
    "w, h, c = 128, 128, 3\n",
    "\n",
    "# to ensure that the generated random numbers are predictable, that is, the same seed value. The generated random numbers are the same. \n",
    "# This parameter will be transferred to the random_state of function train_test_split.\n",
    "seed = 785 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function read_img\n",
    "\n",
    "Create a function that reads all the image data in a folder and resizes the images in a uniform format\n",
    "\n",
    "**input**: function parameter 'path', as the path to the incoming folder\n",
    "\n",
    "**output**: return data, label, flower_dict, image_list_for_plot\n",
    "1. data, ndarray storing images, data.shape = (image_nums, w, h, c)\n",
    "- label, store the label ndarray corresponding to images, label.shape = (image_nums,)\n",
    "- flower_dict, stores a list of number-flower names, e.g. {0: 'daisy', 1: 'dandelion', 2: 'tulips'...}\n",
    "- image_list_for_plot, a list of images to be used for visualization, with internal elements like (images, label_name), 45 images in total, 9 images for each type of flower.\n",
    "\n",
    "**Hint**: you can use, os.listdir, glob.glob, cv2.resize, np.asarray and other methods.\n",
    "\n",
    "**Note**: If you use cv2.imread() function to read the pictures, the color space of the pictures is 'BGR', you need to convert to 'RGB' to facilitate the visualization later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    # Create an empty dictionary corresponding to the number-flower name\n",
    "    flower_dict = {} \n",
    "    # Create a hierarchical list cate for traversing the data folder below the data storage directory, os.path.isdir is used to determine if the file is a directory\n",
    "    cate = [path+x for x in os.listdir(path) if os.path.isdir(path+x)]\n",
    "    # Create empty list for saving images, image tags\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    # Create empty list to hold information about images used for visualization\n",
    "    image_list_for_plot=[]\n",
    "    for idx,folder in enumerate(cate):                                 \n",
    "        counter = 1\n",
    "        flower_dict[idx] = folder.split('/')[-1]\n",
    "        # Use the glob.glob function to search for images that match a specific format \"/*.jpg\" under each hierarchical file and iterate through them\n",
    "        for im in glob.glob(folder+'/*.jpg'):                        \n",
    "            img=cv2.imread(im)                                         \n",
    "            img=cv2.resize(img,(w,h))                           \n",
    "            imgs.append(img)                                           \n",
    "            labels.append(idx)                                         \n",
    "            if counter <= 9:\n",
    "                image_list_for_plot.append((folder.split('/')[-1], cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "                counter+=1\n",
    "    return np.asarray(imgs,np.float32),np.asarray(labels,np.int32),flower_dict, image_list_for_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label, flower_dict, image_list_for_plot=read_img(path)                                              \n",
    "print(\"shape of data:\",data.shape)                                      \n",
    "print(\"shape of label:\",label.shape)  \n",
    "print(len(image_list_for_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "dlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
