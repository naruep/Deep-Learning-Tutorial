{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Introduction\n",
    "\n",
    "### Experimental Background\n",
    "\n",
    "There is a large amount of information in images, which usually requires a lot of language to describe clearly. Among many processing images, classifying them will be the most essential task. In this experiment, we will use convolutional neural network to identify flowers in a real environment, and we will use Keras (backend tensorflow), a deep learning framework, to build a convolutional neural network model to solve the image classification problem.\n",
    "For the dataset, the pictures are divided into five classes: chamomile, tulip, rose, sunflower, dandelion. Photos are not high resolution, about 320x240 pixels. Photos are not reduced to a single size, they Photos are not reduced to a single size, they have different proportions.\n",
    "\n",
    "### Experimental environment\n",
    "\n",
    "- Huawei Modelarts platform\n",
    "    - work environment:Multi-Engine 1.0\n",
    "    - Instance Flavor:8 vCPUs | 32 GiB\n",
    "\n",
    "1. Python 3.6.5\n",
    "2. Tensorflow 1.13.1\n",
    "3. Kears 2.2.4\n",
    "- Matplotlib 3.2.2\n",
    "- Numpy 1.18.5\n",
    "- OpenCV 3.4.1\n",
    "\n",
    "### Purpose of the experiment.\n",
    "\n",
    "1. enhance the understanding of the process of building neural networks using Keras\n",
    "- Explore the impact that unbalanced data can have\n",
    "- Learn how to use mature models to make efficient use of existing datasets\n",
    "\n",
    "**<font color='red'>Note: Don't worry if WARNING or UserWarning appears in the run results, it won't affect the results. </font>**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduce relevant python packages and modules\n",
    "\n",
    "All the functions needed for this experiment are already included here, allowing you to add your own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.10.1\n",
      "  Using cached tensorflow-2.10.1-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.7.0.68-cp37-abi3-win_amd64.whl (38.2 MB)\n",
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.6.3-cp39-cp39-win_amd64.whl (7.2 MB)\n",
      "Requirement already satisfied: packaging in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from tensorflow==2.10.1) (23.0)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.8.0-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Using cached flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.30.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.2.0-py3-none-any.whl (6.6 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from tensorflow==2.10.1) (1.16.0)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Using cached keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-win_amd64.whl (35 kB)\n",
      "Collecting protobuf<3.20,>=3.9.2\n",
      "  Using cached protobuf-3.19.6-cp39-cp39-win_amd64.whl (895 kB)\n",
      "Requirement already satisfied: setuptools in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from tensorflow==2.10.1) (49.2.1)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-15.0.6.1-py2.py3-none-win_amd64.whl (23.2 MB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting numpy>=1.20\n",
      "  Using cached numpy-1.24.2-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.51.1-cp39-cp39-win_amd64.whl (3.7 MB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Using cached tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Using cached tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.4.0-cp39-cp39-win_amd64.whl (2.5 MB)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.4-cp39-cp39-win_amd64.whl (55 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.38.0-py3-none-any.whl (965 kB)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Using cached contourpy-1.0.7-cp39-cp39-win_amd64.whl (160 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Collecting wheel<1.0,>=0.23.0\n",
      "  Using cached wheel-0.38.4-py3-none-any.whl (36 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.16.0-py2.py3-none-any.whl (177 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (6.0.0)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.4-py3-none-any.whl (61 kB)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.0.1-cp39-cp39-win_amd64.whl (96 kB)\n",
      "Collecting urllib3<1.27,>=1.21.1\n",
      "  Using cached urllib3-1.26.14-py2.py3-none-any.whl (140 kB)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "Collecting MarkupSafe>=2.1.1\n",
      "  Using cached MarkupSafe-2.1.2-cp39-cp39-win_amd64.whl (16 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.1) (3.13.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, libclang, keras, flatbuffers, charset-normalizer, wrapt, wheel, urllib3, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, pyparsing, pyasn1-modules, protobuf, pillow, oauthlib, numpy, MarkupSafe, kiwisolver, idna, grpcio, google-pasta, gast, fonttools, cycler, certifi, cachetools, absl-py, werkzeug, requests, opt-einsum, opencv-python, markdown, keras-preprocessing, h5py, google-auth, contourpy, astunparse, requests-oauthlib, matplotlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.2 absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.0 certifi-2022.12.7 charset-normalizer-3.0.1 contourpy-1.0.7 cycler-0.11.0 flatbuffers-23.1.21 fonttools-4.38.0 gast-0.4.0 google-auth-2.16.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.51.1 h5py-3.8.0 idna-3.4 keras-2.10.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 libclang-15.0.6.1 markdown-3.4.1 matplotlib-3.6.3 numpy-1.24.2 oauthlib-3.2.2 opencv-python-4.7.0.68 opt-einsum-3.3.0 pillow-9.4.0 protobuf-3.19.6 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-2.28.2 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.1 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.30.0 termcolor-2.2.0 typing-extensions-4.4.0 urllib3-1.26.14 werkzeug-2.2.2 wheel-0.38.4 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow==2.10.1 opencv-python matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.1-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "Collecting scipy\n",
      "  Using cached scipy-1.10.0-cp39-cp39-win_amd64.whl (42.5 MB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\pythonproject2023\\deep-learning-tutorial\\dlt\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.2.0 scikit-learn-1.2.1 scipy-1.10.0 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U scikit-learn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers include common network layers. \n",
    "# optimizers include common optimizers. \n",
    "# Sequential is used to construct a linear (from beginning to end) network structure.\n",
    "# Model functional model, complex models can be constructed. \n",
    "from keras import layers, optimizers, Sequential, Model\n",
    "# contains models commonly used for migration learning. \n",
    "from keras import applications# is used for image enhancement. \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# common packages: control files and folders. \n",
    "import glob\n",
    "import os\n",
    "# cv2 = opencv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data reading and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define parameters related to dataset reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of the dataset, which is used for training and verification.\n",
    "# path = '../DL _data/flower_photos/'\n",
    "path = '../Deep-Learning-Tutorial/DL _data/flower_photos/'\n",
    "# Scale images. The size is 128*128*3(width * height * channals)\n",
    "w, h, c = 128, 128, 3\n",
    "\n",
    "# to ensure that the generated random numbers are predictable, that is, the same seed value. The generated random numbers are the same. \n",
    "# This parameter will be transferred to the random_state of function train_test_split.\n",
    "seed = 785 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function read_img\n",
    "\n",
    "Create a function that reads all the image data in a folder and resizes the images in a uniform format\n",
    "\n",
    "**input**: function parameter 'path', as the path to the incoming folder\n",
    "\n",
    "**output**: return data, label, flower_dict, image_list_for_plot\n",
    "1. data, ndarray storing images, data.shape = (image_nums, w, h, c)\n",
    "- label, store the label ndarray corresponding to images, label.shape = (image_nums,)\n",
    "- flower_dict, stores a list of number-flower names, e.g. {0: 'daisy', 1: 'dandelion', 2: 'tulips'...}\n",
    "- image_list_for_plot, a list of images to be used for visualization, with internal elements like (images, label_name), 45 images in total, 9 images for each type of flower.\n",
    "\n",
    "**Hint**: you can use, os.listdir, glob.glob, cv2.resize, np.asarray and other methods.\n",
    "\n",
    "**Note**: If you use cv2.imread() function to read the pictures, the color space of the pictures is 'BGR', you need to convert to 'RGB' to facilitate the visualization later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(path):\n",
    "    # Create an empty dictionary corresponding to the number-flower name\n",
    "    flower_dict = {} \n",
    "    # Create a hierarchical list cate for traversing the data folder below the data storage directory, os.path.isdir is used to determine if the file is a directory\n",
    "    cate = [path+x for x in os.listdir(path) if os.path.isdir(path+x)]\n",
    "    # Create empty list for saving images, image tags\n",
    "    imgs=[]\n",
    "    labels=[]\n",
    "    # Create empty list to hold information about images used for visualization\n",
    "    image_list_for_plot=[]\n",
    "    for idx,folder in enumerate(cate):                                 \n",
    "        counter = 1\n",
    "        flower_dict[idx] = folder.split('/')[-1]\n",
    "        # Use the glob.glob function to search for images that match a specific format \"/*.jpg\" under each hierarchical file and iterate through them\n",
    "        for im in glob.glob(folder+'/*.jpg'):                        \n",
    "            img=cv2.imread(im)                                         \n",
    "            img=cv2.resize(img,(w,h))                           \n",
    "            imgs.append(img)                                           \n",
    "            labels.append(idx)                                         \n",
    "            if counter <= 9:\n",
    "                image_list_for_plot.append((folder.split('/')[-1], cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "                counter+=1\n",
    "    return np.asarray(imgs,np.float32),np.asarray(labels,np.int32),flower_dict, image_list_for_plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of data: (3373, 128, 128, 3)\n",
      "shape of label: (3373,)\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "data, label, flower_dict, image_list_for_plot=read_img(path)                                              \n",
    "print(\"shape of data:\",data.shape)                                      \n",
    "print(\"shape of label:\",label.shape)  \n",
    "print(len(image_list_for_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlt",
   "language": "python",
   "name": "dlt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
